<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Zhili&#39;s Website website</title>
    <link>/categories/statistics/</link>
    <description>Recent content in Statistics on Zhili&#39;s Website website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Odds Ratio</title>
      <link>/2022/06/03/odds-ratio/</link>
      <pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/06/03/odds-ratio/</guid>
      <description>Consider the following contingency table for a retrospective study:
   \ Disease(Yes) Disease(No) Total     Treatment 1 a b a+b   Treatment 2 c d c+d    There are two statistics of interest:
  Relative Risk (RR): $\frac{a/(a+b)}{c/(c+b)}$
  Odds ratios (OR): $\frac{a/b}{c/d}$
  Relative risk is easy to understand: it&amp;rsquo;s the ratio of disease probability between two treatment groups.</description>
    </item>
    
    <item>
      <title>Entropy</title>
      <link>/2022/06/02/information-theory/</link>
      <pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/06/02/information-theory/</guid>
      <description>Shannon&amp;rsquo;s Entropy: $H(X) = -\sum_{x \in X} p(x) \log p(x) = E[-\log p(X)]$
(or $H(X) = -\int_{x \in X} p(x) \log p(x) dx$ )
An intuitive explaination: For independent observations $x, y$, their joint density is $p(x,y) = p(x)p(y)$.
Want to obtain their &amp;ldquo;information&amp;rdquo; $h(x)$ with the following property:
  Monotonic w.r.t. $p(x)$: the higher the density is , the more information we get
  Always positive
  Additivity: information gained from $(x,y)$ is the sum of information gained from $x$ and $y$, i.</description>
    </item>
    
    <item>
      <title>FDR Control</title>
      <link>/2022/05/10/fdr-control/</link>
      <pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/05/10/fdr-control/</guid>
      <description>What is False Discovery Rate (FDR)    Multiple Tests Null Alternative     Not Reject TN FN   Reject FP TP    $FDR = E[\frac{FP}{FP + TP}]$.
$(FP + TP)$ are denoted as &amp;ldquo;discoveries&amp;rdquo;, FDR is the expected rate of false outcomes in all discoveries.
How to Control FDR (the B-H procedure) Suppose a total of m tests are conducted. Rank them by p-values low to high, denote as $H_1, .</description>
    </item>
    
  </channel>
</rss>
